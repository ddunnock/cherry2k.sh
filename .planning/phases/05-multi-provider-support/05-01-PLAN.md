---
phase: 05-multi-provider-support
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/core/src/provider/anthropic.rs
  - crates/core/src/provider/mod.rs
autonomous: true

must_haves:
  truths:
    - "Anthropic provider compiles and passes validate_config()"
    - "Anthropic provider streams responses via SSE"
    - "Invalid Anthropic key returns InvalidApiKey error"
    - "Anthropic health_check() verifies connectivity"
  artifacts:
    - path: "crates/core/src/provider/anthropic.rs"
      provides: "Anthropic provider implementation"
      exports: ["AnthropicProvider"]
      min_lines: 150
  key_links:
    - from: "crates/core/src/provider/anthropic.rs"
      to: "AiProvider trait"
      via: "impl AiProvider for AnthropicProvider"
      pattern: "impl AiProvider for AnthropicProvider"
---

<objective>
Implement Anthropic Claude API provider with streaming support.

Purpose: Enable users to use Anthropic's Claude models through Cherry2K, fulfilling PROV-02 requirement.
Output: Working `AnthropicProvider` that implements `AiProvider` trait with SSE streaming.
</objective>

<execution_context>
@/Users/dunnock/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dunnock/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-multi-provider-support/05-RESEARCH.md

# Existing provider implementation to follow
@crates/core/src/provider/trait.rs
@crates/core/src/provider/openai.rs
@crates/core/src/provider/sse.rs
@crates/core/src/provider/types.rs
@crates/core/src/config/types.rs
@crates/core/src/error.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AnthropicProvider implementation</name>
  <files>crates/core/src/provider/anthropic.rs</files>
  <action>
Create `AnthropicProvider` struct implementing `AiProvider` trait.

**Structure:**
```rust
pub struct AnthropicProvider {
    client: Client,
    config: AnthropicConfig,
}
```

**Key implementation details:**

1. **API Endpoint:** `https://api.anthropic.com/v1/messages`

2. **Required Headers:**
   - `x-api-key: {api_key}` (NOT Bearer token like OpenAI)
   - `anthropic-version: 2023-06-01` (REQUIRED - API will 400 without it)
   - `content-type: application/json`

3. **Request Body Format:**
   ```json
   {
     "model": "claude-sonnet-4-20250514",
     "max_tokens": 1024,
     "messages": [{"role": "user", "content": "..."}],
     "stream": true
   }
   ```
   Note: Anthropic requires explicit `max_tokens` - default to 4096.

4. **SSE Event Parsing:**
   Anthropic SSE events have different structure than OpenAI:
   - `content_block_delta` event type contains text in `delta.text`
   - `message_stop` signals end of stream
   - Other events (message_start, content_block_start, etc.) should be ignored

   Create `parse_anthropic_sse_chunk(data: &str) -> Option<String>` function (can be in this file).

5. **`complete()` method:**
   - Use `reqwest_eventsource::RequestBuilderExt::eventsource()` like OpenAI
   - Create stream using `async_stream::try_stream!`
   - Handle SSE events similar to openai.rs but with Anthropic event parsing

6. **`provider_id()`:** Return `"anthropic"`

7. **`validate_config()`:**
   - Check `config.api_key` is Some and non-empty
   - Return `ConfigError::MissingField { field: "anthropic.api_key" }`

8. **`health_check()`:**
   - Hit `https://api.anthropic.com/v1/models` endpoint
   - Include `x-api-key` and `anthropic-version` headers
   - Map status codes: 200-299=Ok, 401=InvalidApiKey, 429=RateLimited, 5xx=Unavailable

**Error handling:**
- 401 -> `ProviderError::InvalidApiKey { provider: "anthropic" }`
- 429 -> `ProviderError::RateLimited` with Retry-After header (default 60s)
- 5xx -> `ProviderError::Unavailable`
- Connection errors -> `ProviderError::RequestFailed`

**Tests (in #[cfg(test)] mod tests):**
- `valid_config_passes()` - api_key present
- `missing_api_key_fails()` - api_key None
- `empty_api_key_fails()` - api_key Some("")
- `provider_id_returns_anthropic()` - returns "anthropic"
- `provider_is_send_sync()` - trait bounds satisfied

Follow the exact patterns from openai.rs for consistency.
  </action>
  <verify>
```bash
cargo check -p cherry2k-core 2>&1 | head -20
cargo test -p cherry2k-core anthropic 2>&1 | tail -20
```
  </verify>
  <done>AnthropicProvider compiles, implements AiProvider trait, all unit tests pass</done>
</task>

<task type="auto">
  <name>Task 2: Export AnthropicProvider from provider module</name>
  <files>crates/core/src/provider/mod.rs</files>
  <action>
Update `crates/core/src/provider/mod.rs` to:

1. Add module declaration: `mod anthropic;`
2. Add public re-export: `pub use anthropic::AnthropicProvider;`

Place these alongside the existing openai module declaration and export.
  </action>
  <verify>
```bash
cargo check -p cherry2k-core 2>&1 | head -10
```
  </verify>
  <done>AnthropicProvider is exported from cherry2k_core::provider module</done>
</task>

</tasks>

<verification>
```bash
# Full check
cargo check -p cherry2k-core
cargo clippy -p cherry2k-core -- -D warnings
cargo test -p cherry2k-core anthropic

# Verify export
cargo doc -p cherry2k-core --no-deps 2>&1 | grep -i anthropic
```
</verification>

<success_criteria>
- AnthropicProvider implements AiProvider trait
- All unit tests pass
- No clippy warnings
- Provider is exported from crate root
</success_criteria>

<output>
After completion, create `.planning/phases/05-multi-provider-support/05-01-SUMMARY.md`
</output>
