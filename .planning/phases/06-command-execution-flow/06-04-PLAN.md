---
phase: 06-command-execution-flow
plan: 04
type: execute
wave: 3
depends_on: ["06-01", "06-02", "06-03"]
files_modified:
  - crates/cli/src/commands/chat.rs
  - crates/core/src/provider/system_prompts.rs
  - crates/core/src/provider/mod.rs
  - crates/core/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "AI responses with bash code blocks trigger command confirmation flow"
    - "User can approve (y), reject (n), or edit (e) suggested commands"
    - "Approved commands execute with real-time output streaming"
    - "Exit status displays after command completion"
    - "Explicit markers (! prefix, /run) force command mode in system prompt"
  artifacts:
    - path: "crates/cli/src/commands/chat.rs"
      provides: "Integrated chat flow with command detection and execution"
    - path: "crates/core/src/provider/system_prompts.rs"
      provides: "System prompt for command mode"
      exports: ["command_mode_system_prompt"]
  key_links:
    - from: "chat.rs"
      to: "intent module"
      via: "detect_intent call"
      pattern: "detect_intent|Intent::"
    - from: "chat.rs"
      to: "execute module"
      via: "execute_command call"
      pattern: "execute_command"
    - from: "chat.rs"
      to: "confirm module"
      via: "confirm_command call"
      pattern: "confirm_command"
---

<objective>
Integrate intent detection, command execution, and confirmation into the chat flow.

Purpose: Complete the command execution flow by connecting all components: detect commands in AI responses, show confirmation prompt, execute approved commands with streaming output, and display exit status.

Output: Fully integrated chat command with command execution capability.
</objective>

<execution_context>
@/Users/dunnock/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dunnock/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-command-execution-flow/06-CONTEXT.md
@.planning/phases/06-command-execution-flow/06-RESEARCH.md
@crates/cli/src/commands/chat.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add command mode system prompt</name>
  <files>crates/core/src/provider/system_prompts.rs, crates/core/src/provider/mod.rs, crates/core/src/lib.rs</files>
  <action>
Create crates/core/src/provider/system_prompts.rs:

```rust
//! System prompts for AI behavior configuration.
//!
//! Provides system prompt snippets that configure AI behavior for different
//! modes of operation.

/// System prompt snippet for command suggestion mode.
///
/// Instructs the AI to respond with bash code blocks when the user
/// wants a command executed. Includes explicit marker documentation.
///
/// This is appended to any existing system prompt.
pub const COMMAND_MODE_PROMPT: &str = r#"
You are a terminal assistant that helps with shell commands.

When the user wants to run a command or perform a shell action:
- Respond with the command in a bash code block like this:
```bash
command here
```
- Keep explanations brief, focus on the command
- If multiple steps needed, suggest one command at a time

When the user wants an explanation or information:
- Provide a clear, concise answer without code blocks
- Only include code blocks if demonstrating syntax

Explicit mode markers (user can force a mode):
- `!` at start or `/run` at start = always suggest a command
- `?` at end = always provide explanation, never suggest command
"#;

/// Get the command mode system prompt.
#[must_use]
pub fn command_mode_system_prompt() -> &'static str {
    COMMAND_MODE_PROMPT
}
```

Update crates/core/src/provider/mod.rs to add:
```rust
mod system_prompts;
pub use system_prompts::{command_mode_system_prompt, COMMAND_MODE_PROMPT};
```

Update crates/core/src/lib.rs to re-export:
```rust
pub use provider::{command_mode_system_prompt, COMMAND_MODE_PROMPT};
```
  </action>
  <verify>cargo check -p cherry2k-core</verify>
  <done>Command mode system prompt available from core crate</done>
</task>

<task type="auto">
  <name>Task 2: Integrate command flow into chat</name>
  <files>crates/cli/src/commands/chat.rs</files>
  <action>
Modify the chat command to:

1. Add imports at top:
```rust
use crate::intent::{detect_intent, Intent};
use crate::execute::{execute_command, display_exit_status};
use crate::confirm::{confirm_command, edit_command, ConfirmResult};
use crate::output::display_suggested_command;
use cherry2k_core::command_mode_system_prompt;
```

2. After collecting the full response (after the streaming loop), add intent detection and command handling:

```rust
// After: writer.flush()?;
// After: println!(); // Blank line after response

// Detect if response contains a command suggestion
match detect_intent(&collected_response) {
    Intent::Command(detected) => {
        // Display the command with syntax highlighting
        display_suggested_command(&detected.command, detected.context.as_deref());

        // Ask for confirmation
        let mut command_to_run = detected.command.clone();
        loop {
            match confirm_command(&command_to_run)? {
                ConfirmResult::Yes => {
                    println!(); // Blank line before execution

                    // Execute with signal handling
                    let result = execute_command(&command_to_run, Some(cancel_token.clone())).await?;

                    // Display exit status
                    display_exit_status(result.status);

                    if result.was_cancelled {
                        println!("Command interrupted.");
                    }
                    break;
                }
                ConfirmResult::No => {
                    println!("Command cancelled.");
                    break;
                }
                ConfirmResult::Edit => {
                    command_to_run = edit_command(&command_to_run)?;
                    // Loop continues to re-confirm
                }
            }
        }
    }
    Intent::Question => {
        // Response was just an explanation, already displayed
        // Nothing more to do
    }
}
```

3. Add the command mode system prompt to the request:
   - Before building CompletionRequest, check if user message starts with `!` or `/run`
   - If so, strip the prefix and add command_mode_system_prompt() to the request
   - Also add it by default (the AI can choose based on context)

```rust
// Before CompletionRequest::new()
let user_message = message.trim();
let (actual_message, force_command_mode) = if user_message.starts_with('!') {
    (&user_message[1..], true)
} else if user_message.starts_with("/run ") {
    (&user_message[5..], true)
} else {
    (user_message, false)
};

// Add system prompt for command mode
let request = CompletionRequest::new()
    .with_system_message(command_mode_system_prompt())
    .with_messages(context.messages)
    .with_message(Message::user(actual_message));
```

Note: The save_message call should use the actual_message (without prefix) for cleaner history.

4. Move the cancel_token setup earlier (before the streaming loop) so it can be reused for command execution.
  </action>
  <verify>cargo check -p cherry2k</verify>
  <done>Chat command integrates intent detection and command execution</done>
</task>

<task type="auto">
  <name>Task 3: Handle edge cases and test</name>
  <files>crates/cli/src/commands/chat.rs</files>
  <action>
Add edge case handling:

1. Handle `?` suffix for forcing question mode:
```rust
let (actual_message, force_question_mode) = if user_message.ends_with('?')
    && !force_command_mode {
    // Only force question mode if not already forced to command mode
    (user_message, true)
} else {
    (user_message, false)
};
```

2. If force_question_mode, skip intent detection and treat as Question:
```rust
if force_question_mode {
    // Skip command detection for explicit questions
    // Response already displayed
} else {
    match detect_intent(&collected_response) {
        // ... existing logic
    }
}
```

3. Ensure the cancel_token is not consumed by the streaming loop so it can be reused:
   - Clone it before the select! loop
   - Use the clone in command execution

Run full test suite to ensure no regressions:
```
cargo test -p cherry2k
```

Also verify with clippy:
```
cargo clippy -p cherry2k -- -D warnings
```
  </action>
  <verify>cargo test -p cherry2k && cargo clippy -p cherry2k -- -D warnings</verify>
  <done>Chat command handles all edge cases, tests pass</done>
</task>

</tasks>

<verification>
- `cargo check -p cherry2k` succeeds
- `cargo test -p cherry2k` all tests pass
- `cargo clippy -p cherry2k -- -D warnings` no warnings
- Manual test:
  - `cherry2k chat "what is my IP"` suggests a command with confirmation
  - `cherry2k chat "! list files"` forces command mode
  - `cherry2k chat "what is rust?"` provides explanation (no command block expected)
</verification>

<success_criteria>
- AI responses with bash code blocks trigger confirmation prompt
- Confirmation flow: y=execute, n=cancel, e=edit
- Executed commands show streaming output + exit status
- `!` prefix forces command mode
- `?` suffix forces question mode (skips command detection)
- No regressions in existing chat functionality
</success_criteria>

<output>
After completion, create `.planning/phases/06-command-execution-flow/06-04-SUMMARY.md`
</output>
